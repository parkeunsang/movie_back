{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8a9373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import django\n",
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'rest.settings')\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea13d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6178422",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('<[a-zA-Z0-9가-힣, ]+>|\\([a-zA-Z0-9가-힣, ]+\\)|\\\"[a-zA-Z0-9가-힣, ]+|\\\"|\\'[a-zA-Z0-9가-힣, ]+\\'|\\[[a-zA-Z0-9가-힣, ]+\\]')\n",
    "pattern_all = re.compile('<.+>|\\(.+\\)|\\\".+|\\\"|\\'.+\\'|\\[.+\\]')\n",
    "pattern_order = re.compile('[0-9 ]+\\.[a-zA-Z0-9가-힣, ]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7267ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b640e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssafy\\sfy\\projects\\final_project\\movie_back\\venv\\lib\\site-packages\\django\\db\\models\\fields\\__init__.py:1416: RuntimeWarning: DateTimeField Movie.release_date received a naive datetime (2000-01-01 00:00:00) while time zone support is active.\n",
      "  warnings.warn(\"DateTimeField %s received a naive datetime (%s)\"\n"
     ]
    }
   ],
   "source": [
    "over2020 = Movie.objects.filter(release_date__gte='2000-01-01 00:00').order_by('-release_date')\n",
    "# movie_titles = [x.title_ko.replace(' ', '') for x in over2020]\n",
    "movie_titles = [re.sub('[:.\\-_ ]', '', x.title_ko) for x in over2020]\n",
    "movie_pks = [x.pk for x in over2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca1adc",
   "metadata": {},
   "source": [
    "## Keyword로 urls 찾기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029669f",
   "metadata": {},
   "source": [
    "### 구글"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f4c4137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(url_data, keyword_origin):\n",
    "    url = f'https://www.google.com/search'    \n",
    "    url_data[keyword_origin] = []\n",
    "    keyword = f'{keyword_origin} 영화 추천'\n",
    "    keyword = keyword.replace(' ', '+')\n",
    "    for start in tqdm(range(0, 101, 10)):\n",
    "        params = {\n",
    "            'q': keyword,\n",
    "            'start': start\n",
    "        }\n",
    "        soup = bs(requests.get(url, headers=headers, params=params).text, 'lxml')\n",
    "        table = soup.find_all('div', {'class':'g'})\n",
    "        if start == 0:\n",
    "            l = 1\n",
    "        else:\n",
    "            l = 0\n",
    "\n",
    "        r = len(table)\n",
    "        for i in range(l, r):\n",
    "            title = table[i].find('h3').text.strip()\n",
    "            url_link = table[i].find('div', {'class':'yuRUbf'}).find('a')['href']\n",
    "            url_data[keyword_origin].append({\n",
    "                'title': title,\n",
    "                'url_link': url_link\n",
    "            })\n",
    "    return url_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135bc51",
   "metadata": {},
   "source": [
    "### 네이버"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "6ae766c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://m.search.naver.com/search.naver?page=2&query=%EB%B0%98%EC%A0%84+%EC%98%81%ED%99%94+%EC%B6%94%EC%B2%9C&sm=mtb_pge&start=1&where=m_web'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "52a0ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "511f3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_origin = '반전'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "c6132af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data[keyword_origin] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "f6efb4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = f'{keyword_origin} 영화 추천'\n",
    "keyword = keyword.replace(' ', '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "6ffa37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start in tqdm(range(0, 101, 10)):\n",
    "    params = {\n",
    "        'q': keyword,\n",
    "        'start': start\n",
    "    }\n",
    "\n",
    "    soup = bs(requests.get(url, headers=headers, params=params).text, 'lxml')\n",
    "    table = soup.find_all('div', {'class':'g'})\n",
    "    if start == 0:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = 0\n",
    "\n",
    "    r = len(table)\n",
    "    for i in range(l, r):\n",
    "        title = table[i].find('h3').text.strip()\n",
    "        url_link = table[i].find('div', {'class':'yuRUbf'}).find('a')['href']\n",
    "        url_data[keyword_origin].append({\n",
    "            'title': title,\n",
    "            'url_link': url_link\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "ce49ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(requests.get(url, headers=headers, params=params).text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "5bd822d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://jennablog.kr/426'"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('div', {'class':'total_tit_group'})[1].find('a')['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a671e23",
   "metadata": {},
   "source": [
    "## Urls에서 영화 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a37729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_titles(arr):\n",
    "    arr = [re.sub('[:.\\-_\\xa0]', '', x).strip() for x in arr]  # 특수문자 제거\n",
    "    arr = [x for x in arr if not x.isdigit() and len(x) > 1]  # 그냥 이름이 숫자인 영화랑 한글자인 영화는 제외하기로\n",
    "    \n",
    "    dummies_contain = ['폰트', '본문', '블로그', '검색', '공유', '추천', '댓글']\n",
    "    dummies_equal = ['공감', '상세보기', '태그', 'Password', '홈', '링크', '.', '()', '로그인',\n",
    "                    '부동산', 'TAG', '서울', '부산', 'Calendar', 'Tag', '음악', 'Next', '네이버', '팔로우',\n",
    "                    '공포', '패션', '연애', '청소년', '스포주의', '스포']\n",
    "    temp = []\n",
    "    for text in arr:\n",
    "        if text in dummies_equal:\n",
    "            continue\n",
    "        for dummy in dummies_contain:\n",
    "            if dummy in text:\n",
    "                break\n",
    "        else:\n",
    "            temp.append(text)\n",
    "    \n",
    "    result = []\n",
    "    for mt in set(temp):\n",
    "        if mt.replace(' ', '') in movie_titles:\n",
    "            result.append(mt.replace(' ', ''))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6cbf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 패턴으로 check\n",
    "def check_pattern(soup):\n",
    "    unique1 = []  # [title], 'title' 이런 것들\n",
    "    unique2 = []  # 연도랑 같이 있는 것들\n",
    "    unique3 = []  # 1. title 이런 것들\n",
    "    for sf in soup.find_all():\n",
    "        text = sf.text.strip()\n",
    "        if len(text) < 50:\n",
    "            compiled1 = re.search(pattern, text)\n",
    "            compiled2 = re.search(pattern_all, text)\n",
    "            compiled3 = re.search(pattern_order, text)\n",
    "            if compiled1:\n",
    "                unique1.append(compiled1.group()[1:-1])\n",
    "            if compiled2:\n",
    "                unique2.append(text.replace(compiled2.group(), '').strip())\n",
    "            if compiled3:\n",
    "                unique3.append(compiled3.group().split('.')[1].strip())\n",
    "    #         if compiled1:\n",
    "    #             unique1.append((compiled1.group()[1:-1], sf.name, tuple(sf.get_attribute_list('class'))))\n",
    "    #         if compiled2:\n",
    "    #             unique2.append((text.replace(compiled2.group(), '').strip(), sf.name, tuple(sf.get_attribute_list('class'))))\n",
    "    #         if compiled3:\n",
    "    #             unique3.append((compiled3.group().split('.')[1].strip(), sf.name, tuple(sf.get_attribute_list('class'))))\n",
    "    return get_movie_titles(unique1) + get_movie_titles(unique2) + get_movie_titles(unique3)  # 특정한 형식이 갖춰져있는 추천영화들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672f233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 볼드체나 h태그로\n",
    "def check_tags(soup):\n",
    "    possible_tags = []\n",
    "    for i in range(1, 6):\n",
    "        possible_tags.extend(soup.find_all(f'h{i}'))\n",
    "    possible_tags.extend(soup.find_all('b'))\n",
    "    possible_tags.extend(soup.find_all('strong'))\n",
    "    \n",
    "    possible_tags = [x.text for x in possible_tags]\n",
    "    return get_movie_titles(possible_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dcfbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 없으면 다 check\n",
    "def check_all(soup):\n",
    "    all_tags = [(x.text.strip(), x.name, tuple(x.get_attribute_list('class'))) for x in soup.find_all() if x.text]\n",
    "    all_tags = [x for x in all_tags if x[0] != '' and len(x[0]) < 20]\n",
    "    all_text = [re.sub('[:.-_\\xa0]', '', x[0]).strip() for x in all_tags]\n",
    "    return get_movie_titles(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc4f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "def movie_order(kws):\n",
    "    temp = []\n",
    "    for k in kws:\n",
    "        temp += k\n",
    "    return list(OrderedDict(Counter(temp).most_common()).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc63741",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_data = {}\n",
    "keyword_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "id": "4412ef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:11<00:00,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "keyword_origin = '이별'\n",
    "url_data = get_urls(url_data, keyword_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "id": "f34b8f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 102/102 [01:24<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "kws = []\n",
    "for url_d in tqdm(url_data[keyword_origin]):\n",
    "    url = url_d['url_link']\n",
    "    if keyword_origin not in url_d['title'].replace(' ', '') or '영화' not in url_d['title']:  # 글제목이 반전영화와 관계가 없을경우\n",
    "        continue\n",
    "    if 'youtube' in url or 'namu.wiki' in url:\n",
    "        continue\n",
    "    try:\n",
    "        soup = bs(requests.get(url, headers=headers).text)\n",
    "    except:\n",
    "        print('error', url)\n",
    "        continue\n",
    "    pattern_movies = check_pattern(soup)\n",
    "    possible_tags = check_tags(soup)\n",
    "    all_tags = check_all(soup)\n",
    "    \n",
    "#     movie_keywords = {}\n",
    "#     movie_keywords['title'] = url_d['title']\n",
    "#     movie_keywords['url'] = url\n",
    "#     movie_keywords['pattern'] = pattern_movies\n",
    "#     movie_keywords['tags'] = possible_tags\n",
    "#     movie_keywords['all'] = all_tags\n",
    "#     temp.append(movie_keywords)\n",
    "    mts = list(set(pattern_movies + possible_tags + all_tags))  # 해당 글의 영화제목들\n",
    "    if mts:\n",
    "        kws.append(mts)\n",
    "keyword_data[keyword_origin] = kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "id": "a2eeed96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['반전', '비올때', '신나는', '이별'])"
      ]
     },
     "execution_count": 1209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "id": "7721fa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('이별계약', 8),\n",
       " ('이터널선샤인', 7),\n",
       " ('연애의온도', 5),\n",
       " ('이프온리', 4),\n",
       " ('500일의썸머', 4),\n",
       " ('로맨스', 4),\n",
       " ('클로저', 3),\n",
       " ('사랑', 3),\n",
       " ('라이프', 3),\n",
       " ('친구', 3)]"
      ]
     },
     "execution_count": 1238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_order(keyword_data['이별'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "id": "f0744165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173090"
      ]
     },
     "execution_count": 1262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles.index('이별계약')\n",
    "Movie.objects.filter(pk=movie_pks[173090])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "id": "cbfb7130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Movie: Movie object (195921)>"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Movie.objects.filter(pk=movie_pks[173090])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "514d432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e0300ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "km.movie_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275115c",
   "metadata": {},
   "source": [
    "### 불러와서 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "id": "1c9ea2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('url_data.pkl', 'wb') as f:\n",
    "    pickle.dump(url_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "id": "46e93bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keyword_data.pkl', 'wb') as f:\n",
    "    pickle.dump(keyword_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b67b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8bfc7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('url_data.pkl', 'rb') as f:\n",
    "    url_data = pickle.load(f) # 단 한줄씩 읽어옴\n",
    "with open('keyword_data.pkl', 'rb') as f:\n",
    "    keyword_data = pickle.load(f) # 단 한줄씩 읽어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e562ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(keyword_data.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a308622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword 저장\n",
    "for key in keyword_data.keys():\n",
    "    keyword = Keyword()\n",
    "    keyword.word = key\n",
    "    keyword.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bdcf675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 관계 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1fe53f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(keyword_data.keys()):\n",
    "\n",
    "    word_pk = Keyword.objects.filter(word=key)[0].pk\n",
    "    mv_od = movie_order(keyword_data[key])\n",
    "    maximum = mv_od[0][1]\n",
    "    minimum = min(2, 10 / maximum)\n",
    "\n",
    "    for mo in mv_od:\n",
    "        km = KM()\n",
    "        idx = movie_titles.index(mo[0])\n",
    "        movie_pk = Movie.objects.filter(pk=movie_pks[idx])[0].pk\n",
    "\n",
    "        km.word_id = word_pk\n",
    "        km.movie_id = movie_pk\n",
    "        km.score = round(minimum + (10 - minimum) * (mo[1]-1)/maximum, 2)\n",
    "        km.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d26f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
